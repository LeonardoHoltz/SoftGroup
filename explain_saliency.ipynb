{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Captum tests\n",
    "\n",
    "Needed to modify the model code slightly, so the rest of the repo won't work\n",
    "\n",
    "Don't forget to download the models from the README"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "import os.path as osp\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import yaml\n",
    "from munch import Munch\n",
    "from softgroup.data import build_dataloader, build_dataset\n",
    "from softgroup.model import SoftGroup\n",
    "from softgroup.util import (collect_results_cpu, get_dist_info, get_root_logger, init_dist,\n",
    "                            is_main_process, load_checkpoint, rle_decode)\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "from tqdm import tqdm\n",
    "\n",
    "args = argparse.Namespace(\n",
    "    config=\"./configs/softgroup/softgroup_s3dis_fold5.yaml\",\n",
    "    # Download and extract this\n",
    "    checkpoint=\"./models/softgroup_s3dis_spconv2.pth\",\n",
    "    dist=False,\n",
    ")\n",
    "\n",
    "cfg_txt = open(args.config, 'r').read()\n",
    "cfg = Munch.fromDict(yaml.safe_load(cfg_txt))\n",
    "logger = get_root_logger()\n",
    "\n",
    "model = SoftGroup(**cfg.model).cuda()\n",
    "logger.info(f'Load state dict from {args.checkpoint}')\n",
    "load_checkpoint(args.checkpoint, logger, model)\n",
    "\n",
    "dataset = build_dataset(cfg.data.test, logger)\n",
    "dataloader = build_dataloader(dataset, training=False, dist=args.dist, **cfg.dataloader.test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for i, batch in tqdm(enumerate(dataloader), total=len(dataset)):\n",
    "        # Set params here so the model only takes coords and feats as input\n",
    "        #model.set_params(**batch)\n",
    "        #result = model(batch['coords_float'], batch['feats'])\n",
    "        #results.append(result)\n",
    "        print(batch[ \"scan_ids\" ])\n",
    "        # selected rooms: 4, 22\n",
    "        #if i + 1 == 4:\n",
    "        if batch[ \"scan_ids\" ] == ['Area_5_storage_2']:\n",
    "            break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(batch.keys())\n",
    "#print(batch['voxel_coords'].shape)\n",
    "print(batch['coords_float'].shape)\n",
    "print(batch['feats'].shape)\n",
    "#batch['scan_ids']\n",
    "#batch['batch_idxs']\n",
    "#batch['voxel_coords']\n",
    "#batch['p2v_map']\n",
    "#batch['v2p_map']\n",
    "#print(batch['coords_float'])\n",
    "#print(batch['feats'])\n",
    "#batch['semantic_labels']\n",
    "#batch['instance_labels']\n",
    "#batch['instance_pointnum']\n",
    "#batch['instance_cls']\n",
    "#batch['pt_offset_labels']\n",
    "#batch['spatial_shape']\n",
    "#batch['batch_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create point cloud line by the points quantity\n",
    "distance = 2.00\n",
    "batch_coords_x = torch.arange(0, batch['coords_float'].shape[0] * distance, distance) # arithmetic progression of points\n",
    "batch_coords_y = torch.full(batch_coords_x.shape, torch.mean(batch['coords_float'][:, 1]).item())\n",
    "batch_coords_z = torch.full(batch_coords_x.shape, torch.mean(batch['coords_float'][:, 2]).item())\n",
    "batch_coords_x = batch_coords_x.reshape(-1, 1)\n",
    "batch_coords_y = batch_coords_y.reshape(-1, 1)\n",
    "batch_coords_z = batch_coords_z.reshape(-1, 1)\n",
    "batch_coords = torch.concat((batch_coords_x, batch_coords_y, batch_coords_z), 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show point cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nubilum_bk.utils.nubilum_utils as nb_utils\n",
    "import nubilum.utils as nb_utils\n",
    "def show_color_cloud(coords, colors):\n",
    "    colors = (colors + 1)/2*255 # change color interval from [-1, 1] to [0, 255]\n",
    "    nb_utils.show_point_cloud(coords, colors)\n",
    "    #nb_utils.nubilum_utils.show_point_cloud(batch[\"coords_float\"], colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show_color_cloud(batch_coords, batch['feats'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "pio.renderers.default = \"browser\"\n",
    "\n",
    "model.train()\n",
    "model.set_params(**batch)\n",
    "\n",
    "# output always have this format: dict_keys(['scan_id', 'semantic_labels', 'instance_labels', 'coords_float', 'color_feats', 'semantic_preds', 'offset_preds', 'offset_labels', 'semantic_scores'])\n",
    "# remember that the order of points in the output is different from the batch\n",
    "\n",
    "out = model(batch_coords, batch['feats'])\n",
    "\n",
    "instance_labels = torch.LongTensor(out['instance_labels'])\n",
    "\n",
    "classes = {0: 'ceiling', 1: 'floor', 2: 'wall', 3: 'beam', 4: 'column', 5: 'window', 6: 'door', 7: 'chair', 8: 'table', 9: 'bookcase', 10: 'sofa', 11: 'board', 12: 'clutter'}\n",
    "\n",
    "nb_utils.show_point_cloud_classification_plotly(out['coords_float'], out['semantic_preds'], instance_labels, classes_dict=classes)\n",
    "#nb_utils.show_point_cloud_classification_k3d(batch['coords_float'], out['semantic_preds'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from nubilum_local_bk.forward.nubilum_forward import InstanceWrappedModel, PointWrappedModel, SummarizedWrappedModel\n",
    "from nubilum.forward import InstanceWrappedModel, PointWrappedModel, SummarizedWrappedModel\n",
    "        \n",
    "instance_wrap = InstanceWrappedModel(model)\n",
    "point_wrap = PointWrappedModel(model)\n",
    "summarized_wrap = SummarizedWrappedModel(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saliency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from nubilum_local_bk.attr.nubilum_saliency import NubilumSaliency\n",
    "from nubilum.attr import NubilumSaliency\n",
    "\n",
    "model.train() # TODO: See if this works, if not, use model.train\n",
    "model.set_params(**batch)\n",
    "\n",
    "coords_float = batch['coords_float'].float().to(\"cuda:0\").requires_grad_(True)\n",
    "feats = batch['feats'].float().to(\"cuda:0\").requires_grad_(True)\n",
    "\n",
    "sl_instance = NubilumSaliency(instance_wrap)\n",
    "sl_point = NubilumSaliency(point_wrap)\n",
    "sl_summary = NubilumSaliency(summarized_wrap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outputs\n",
    "    0: 'ceiling',\n",
    "    1: 'floor',\n",
    "    2: 'wall',\n",
    "    3: 'beam',\n",
    "    4: 'column',\n",
    "    5: 'window',\n",
    "    6: 'door',\n",
    "    7: 'chair',\n",
    "    8: 'table',\n",
    "    9: 'bookcase',\n",
    "    10: 'sofa',\n",
    "    11: 'board',\n",
    "    12: 'clutter',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point of interest on evidence in the Point Cloud\n",
    "\n",
    "# REMEMBER TO USE ALWAYS THE POINTS INDICES FROM THE OUTPUT, THANKS SOFTGROUP FOR CHANGING THEM :DD\n",
    "\n",
    "poi = 0\n",
    "ioi = 16\n",
    "\n",
    "ceiling = torch.tensor(0, device=\"cuda\")\n",
    "floor = torch.tensor(1, device=\"cuda\")\n",
    "wall = torch.tensor(2, device=\"cuda\")\n",
    "windows = torch.tensor(5, device=\"cuda\")\n",
    "doors = torch.tensor(6, device=\"cuda\")\n",
    "chairs = torch.tensor(7, device=\"cuda\") # remember to always change this when changing the analysis\n",
    "tables = torch.tensor(8, device=\"cuda\")\n",
    "bookcases = torch.tensor(9, device=\"cuda\")\n",
    "clutter = torch.tensor(12, device=\"cuda\")\n",
    "#nb_utils.show_poi(poi, out[\"coords_float\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_scale_attributes(attributes: np.array, signed=False):\n",
    "    log_attr = np.log10(np.abs(attributes) + 1e-10)\n",
    "    if signed: # to verify the positive and negative contributions\n",
    "        signs = np.sign(attributes)\n",
    "        signed_log_attr = signs * (log_attr + abs(np.min(log_attr))) # It reverts the abs procedure done to calculate the log before\n",
    "        return signed_log_attr\n",
    "    else:\n",
    "        return log_attr"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instance Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_wrap_attributes = sl_instance.attribute(inputs=(coords_float, feats), target=chairs, additional_forward_args=(out['instance_labels'], ioi, 'semantic_scores'))\n",
    "inst_point_attrs = nb_utils.sum_point_attributes(instance_wrap_attributes)\n",
    "#nb_utils.explain_plotly(inst_point_attrs, batch['coords_float'])\n",
    "nb_utils.explain_k3d(inst_point_attrs, batch['coords_float'], \"All attributes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_wrap_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chair importance ratio\n",
    "instance_mask = batch['instance_labels'] == ioi\n",
    "chair_attr = inst_point_attrs[instance_mask]\n",
    "\n",
    "ratio = chair_attr.sum() / inst_point_attrs.sum()\n",
    "print(ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_coords = batch_coords.to('cuda:0')\n",
    "point_wrap_attributes = sl_point.attribute((batch_coords, feats), target = ceiling, additional_forward_args=(poi, 'semantic_scores')) # coords were changed for rf test\n",
    "point_point_attrs = nb_utils.sum_point_attributes(point_wrap_attributes)\n",
    "point_log_attr = log_scale_attributes(point_point_attrs.cpu().detach().numpy())\n",
    "print(point_log_attr)\n",
    "nb_utils.explain_plotly(torch.tensor(point_log_attr), batch_coords.cpu())\n",
    "#nb_utils.explain_k3d(torch.tensor(point_log_attr), batch_coords.cpu(), \"All attributes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_wrap_attributes = sl_summary.attribute((coords_float, feats), target = bookcases, additional_forward_args=('semantic_scores'))\n",
    "summ_point_attrs = nb_utils.sum_point_attributes(summary_wrap_attributes)\n",
    "#nb_utils.explain_plotly(inst_point_attrs, batch['coords_float'])\n",
    "nb_utils.explain_k3d(summ_point_attrs, batch['coords_float'], \"All attributes\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sempre que se estiver usando o termo \"**atributo**\", estamos falando da importância ou score de relevância do input para um determinado output obtido através de um modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_point_attrs = nb_utils.sum_point_attributes(instance_wrap_attributes)\n",
    "point_point_attrs = nb_utils.sum_point_attributes(point_wrap_attributes)\n",
    "summ_point_attrs = nb_utils.sum_point_attributes(summary_wrap_attributes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show attribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instance\n",
    "nb_utils.explain_plotly(inst_point_attrs, batch['coords_float'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_utils.explain_k3d(inst_point_attrs, batch['coords_float'], \"All attributes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "softgroup_pp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c176f5d7114dce7e56e18aa449730192889d0acf94cfa3760f893087531eb97f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
