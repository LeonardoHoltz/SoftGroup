{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Captum tests\n",
    "\n",
    "Needed to modify the model code slightly, so the rest of the repo won't work\n",
    "\n",
    "Don't forget to download the models from the README"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "import os.path as osp\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import yaml\n",
    "from munch import Munch\n",
    "from softgroup.data import build_dataloader, build_dataset\n",
    "from softgroup.model import SoftGroup\n",
    "from softgroup.util import (collect_results_cpu, get_dist_info, get_root_logger, init_dist,\n",
    "                            is_main_process, load_checkpoint, rle_decode)\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "from tqdm import tqdm\n",
    "\n",
    "args = argparse.Namespace(\n",
    "    config=\"./configs/softgroup/softgroup_s3dis_fold5.yaml\",\n",
    "    # Download and extract this\n",
    "    checkpoint=\"./models/softgroup_s3dis_spconv2.pth\",\n",
    "    dist=False,\n",
    ")\n",
    "\n",
    "cfg_txt = open(args.config, 'r').read()\n",
    "cfg = Munch.fromDict(yaml.safe_load(cfg_txt))\n",
    "logger = get_root_logger()\n",
    "\n",
    "model = SoftGroup(**cfg.model).cuda()\n",
    "logger.info(f'Load state dict from {args.checkpoint}')\n",
    "load_checkpoint(args.checkpoint, logger, model)\n",
    "\n",
    "dataset = build_dataset(cfg.data.test, logger)\n",
    "dataloader = build_dataloader(dataset, training=False, dist=args.dist, **cfg.dataloader.test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for i, batch in tqdm(enumerate(dataloader), total=len(dataset)):\n",
    "        # Set params here so the model only takes coords and feats as input\n",
    "        #model.set_params(**batch)\n",
    "        #result = model(batch['coords_float'], batch['feats'])\n",
    "        #results.append(result)\n",
    "        #print(batch[ \"scan_ids\" ])\n",
    "        # selected rooms: 4\n",
    "        if i + 1 == 4:\n",
    "            break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(batch.keys())\n",
    "#print(batch['voxel_coords'].shape)\n",
    "#print(batch['coords_float'].shape)\n",
    "#print(batch['feats'].shape)\n",
    "#batch['scan_ids']\n",
    "#batch['batch_idxs']\n",
    "#batch['voxel_coords']\n",
    "#batch['p2v_map']\n",
    "#batch['v2p_map']\n",
    "#print(batch['coords_float'])\n",
    "#batch['feats']\n",
    "#batch['semantic_labels']\n",
    "#batch['instance_labels']\n",
    "#batch['instance_pointnum']\n",
    "#batch['instance_cls']\n",
    "#batch['pt_offset_labels']\n",
    "#batch['spatial_shape']\n",
    "#batch['batch_size']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show point cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nubilum.utils.nubilum_utils as nb_utils\n",
    "def show_color_cloud(batch):\n",
    "    colors = (batch['feats'] + 1)/2*255 # change color interval from [-1, 1] to [0, 255]\n",
    "    nb_utils.show_point_cloud(batch[\"coords_float\"], colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_color_cloud(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outputs\n",
    "\n",
    "    0: 'ceiling',\n",
    "    1: 'floor',\n",
    "    2: 'wall',\n",
    "    3: 'beam',\n",
    "    4: 'column',\n",
    "    5: 'window',\n",
    "    6: 'door',\n",
    "    7: 'chair',\n",
    "    8: 'table',\n",
    "    9: 'bookcase',\n",
    "    10: 'sofa',\n",
    "    11: 'board',\n",
    "    12: 'clutter',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "pio.renderers.default = \"browser\"\n",
    "\n",
    "model.train()\n",
    "model.set_params(**batch)\n",
    "\n",
    "# output always have this format: dict_keys(['scan_id', 'semantic_labels', 'instance_labels', 'coords_float', 'color_feats', 'semantic_preds', 'offset_preds', 'offset_labels', 'semantic_scores'])\n",
    "# remember that the order of points in the output is different from the batch\n",
    "\n",
    "out = model(batch['coords_float'], batch['feats'])\n",
    "\n",
    "instance_labels = torch.LongTensor(out['instance_labels'])\n",
    "\n",
    "classes = {0: 'ceiling', 1: 'floor', 2: 'wall', 3: 'beam', 4: 'column', 5: 'window', 6: 'door', 7: 'chair', 8: 'table', 9: 'bookcase', 10: 'sofa', 11: 'board', 12: 'clutter'}\n",
    "\n",
    "nb_utils.show_point_cloud_classification_plotly(out['coords_float'], out['semantic_preds'], instance_labels, classes_dict=classes)\n",
    "#nb_utils.show_point_cloud_classification_k3d(batch['coords_float'], out['semantic_preds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#model.train()\n",
    "#model.set_params(**batch)\n",
    "out = model(batch['coords_float'], batch['feats'])\n",
    "#print(out[:10])\n",
    "# N = number of points\n",
    "# K = number of classes\n",
    "print(out.keys())\n",
    "print(out['semantic_scores'].shape) # N x K # out is the probabilities for each possible target. The sum of all prob. is 1.\n",
    "\n",
    "# Chose a random point of interest\n",
    "poi = 145 # [index, class]\n",
    "confidences = out[poi].cpu().numpy()\n",
    "plt.imshow(confidences.reshape(-1,1))\n",
    "plt.title(f\"Confidences for point of interest {poi}\")\n",
    "confidence, classification = out[poi].max(0)\n",
    "print(confidence)   # Confidence is the probability of the class target choosed by the model. The biggest prob.\n",
    "print(classification) # Classification is the class index.\n",
    "print(classification.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline Point Cloud\n",
    "baseline_coords, baseline_colors = nb_utils.create_baseline_point_cloud(batch[\"coords_float\"])\n",
    "baseline_coords = baseline_coords.float().to(\"cuda:0\").requires_grad_(True)\n",
    "baseline_colors = baseline_colors.float().to(\"cuda:0\").requires_grad_(True)\n",
    "#print(baseline_coords.shape)\n",
    "#print(baseline_colors.shape)\n",
    "#nb_utils.show_point_cloud(baseline_coords, baseline_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline classification\n",
    "baseline_out = out = model(baseline_coords, baseline_colors)\n",
    "\n",
    "instance_labels = torch.LongTensor(baseline_out['instance_labels'])\n",
    "\n",
    "nb_utils.show_point_cloud_classification_plotly(baseline_out['coords_float'], baseline_out['semantic_preds'], instance_labels, classes_dict=classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nubilum.forward.nubilum_forward import InstanceWrappedModel, PointWrappedModel, SummarizedWrappedModel \n",
    "        \n",
    "instance_wrap = InstanceWrappedModel(model)\n",
    "point_wrap = PointWrappedModel(model)\n",
    "summarized_wrap = SummarizedWrappedModel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INTEGRATED GRADIENTS BASED ON OBJECT INSTANCE\n",
    "from captum.attr import IntegratedGradients\n",
    "from nubilum.attr.nubilum_integrated_gradients import NubilumIntegratedGradients\n",
    "\n",
    "model.train() # TODO: See if this works, if not, use model.train\n",
    "model.set_params(**batch)\n",
    "\n",
    "coords_float = batch['coords_float'].float().to(\"cuda:0\").requires_grad_(True)\n",
    "feats = batch['feats'].float().to(\"cuda:0\").requires_grad_(True)\n",
    "\n",
    "ig_instance = NubilumIntegratedGradients(instance_wrap)\n",
    "ig_point = NubilumIntegratedGradients(point_wrap)\n",
    "ig_summary = NubilumIntegratedGradients(summarized_wrap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point of interest on evidence in the Point Cloud\n",
    "\n",
    "# REMEMBER TO USE ALWAYS THE POINTS INDICES FROM THE OUTPUT, THANKS SOFTGROUP FOR CHANGING THEM :DD\n",
    "\n",
    "poi = 243012 # table leg with conflict\n",
    "ioi = 16\n",
    "ioi_floor = 39\n",
    "chairs = torch.tensor(7, device=\"cuda\") # remember to always change this when changing the analysis\n",
    "tables = torch.tensor(8, device=\"cuda\")\n",
    "bookcases = torch.tensor(9, device=\"cuda\")\n",
    "windows = torch.tensor(5, device=\"cuda\")\n",
    "doors = torch.tensor(6, device=\"cuda\")\n",
    "floor = torch.tensor(1, device=\"cuda\")\n",
    "#nb_utils.show_poi(poi, out[\"coords_float\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_wrap_attributes = ig_instance.attribute((coords_float, feats), baselines=(baseline_coords, baseline_colors), target=chairs, additional_forward_args=(out['instance_labels'], ioi, 'semantic_scores'), n_steps=50, method='riemann_middle', internal_batch_size=1)\n",
    "inst_point_attrs = nb_utils.sum_point_attributes(instance_wrap_attributes)\n",
    "#nb_utils.explain_plotly(inst_point_attrs, batch['coords_float'])\n",
    "nb_utils.explain_k3d(inst_point_attrs, batch['coords_float'], \"All attributes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chair importance ratio\n",
    "instance_mask = batch['instance_labels'] == ioi\n",
    "chair_attr = inst_point_attrs[instance_mask]\n",
    "\n",
    "ratio = chair_attr.sum() / inst_point_attrs.sum()\n",
    "print(ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "floor_ig_attributes = ig_instance.attribute((coords_float, feats), baselines=(baseline_coords, baseline_colors), target=floor, additional_forward_args=(out['instance_labels'], ioi_floor, 'semantic_scores'), n_steps=50, method='riemann_middle', internal_batch_size=1)\n",
    "floor_inst_point_attrs = nb_utils.sum_point_attributes(floor_ig_attributes)\n",
    "#nb_utils.explain_plotly(inst_point_attrs, batch['coords_float'])\n",
    "nb_utils.explain_k3d(floor_inst_point_attrs, batch['coords_float'], \"All attributes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chair importance ratio\n",
    "floor_instance_mask = batch['instance_labels'] == ioi_floor\n",
    "floor_attr = floor_inst_point_attrs[floor_instance_mask]\n",
    "\n",
    "floor_ratio = floor_attr.sum() / floor_inst_point_attrs.sum()\n",
    "print(floor_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_wrap_attributes = ig_point.attribute((coords_float, feats), baselines=(baseline_coords, baseline_colors), target=chairs, additional_forward_args=(poi, 'semantic_scores'), method='riemann_middle', internal_batch_size=1)\n",
    "point_point_attrs = nb_utils.sum_point_attributes(point_wrap_attributes)\n",
    "#nb_utils.explain_plotly(inst_point_attrs, batch['coords_float'])\n",
    "nb_utils.explain_k3d(point_point_attrs, batch['coords_float'], \"All attributes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_wrap_attributes = ig_summary.attribute((coords_float, feats), baselines=(baseline_coords, baseline_colors), target=tables, additional_forward_args=('semantic_scores'), method='riemann_middle', internal_batch_size=1)\n",
    "summ_point_attrs = nb_utils.sum_point_attributes(summary_wrap_attributes)\n",
    "#nb_utils.explain_plotly(inst_point_attrs, batch['coords_float'])\n",
    "nb_utils.explain_k3d(summ_point_attrs, batch['coords_float'], \"All attributes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_wrap_attributes = ig_instance.attribute((coords_float, feats), target=chairs, additional_forward_args=(out['instance_labels'], ioi, 'semantic_scores'), n_steps=50, method='riemann_middle', internal_batch_size=1)\n",
    "inst_point_attrs = nb_utils.sum_point_attributes(instance_wrap_attributes)\n",
    "#nb_utils.explain_plotly(inst_point_attrs, batch['coords_float'])\n",
    "nb_utils.explain_k3d(inst_point_attrs, batch['coords_float'], \"All attributes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_wrap_attributes = ig_summary.attribute((coords_float, feats), target=tables, additional_forward_args=('semantic_scores'), method='riemann_middle', internal_batch_size=1)\n",
    "summ_point_attrs = nb_utils.sum_point_attributes(summary_wrap_attributes)\n",
    "#nb_utils.explain_plotly(inst_point_attrs, batch['coords_float'])\n",
    "nb_utils.explain_k3d(summ_point_attrs, batch['coords_float'], \"All attributes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "softgroup_pp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c176f5d7114dce7e56e18aa449730192889d0acf94cfa3760f893087531eb97f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
