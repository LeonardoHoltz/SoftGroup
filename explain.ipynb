{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Captum tests\n",
    "\n",
    "Needed to modify the model code slightly, so the rest of the repo won't work\n",
    "\n",
    "Don't forget to download the models from the README"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "import os.path as osp\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import yaml\n",
    "from munch import Munch\n",
    "from softgroup.data import build_dataloader, build_dataset\n",
    "from softgroup.model import SoftGroup\n",
    "from softgroup.util import (collect_results_cpu, get_dist_info, get_root_logger, init_dist,\n",
    "                            is_main_process, load_checkpoint, rle_decode)\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "from tqdm import tqdm\n",
    "\n",
    "args = argparse.Namespace(\n",
    "    config=\"./configs/softgroup/softgroup_s3dis_fold5.yaml\",\n",
    "    # Download and extract this\n",
    "    checkpoint=\"./models/softgroup_s3dis_spconv2.pth\",\n",
    "    dist=False,\n",
    ")\n",
    "\n",
    "cfg_txt = open(args.config, 'r').read()\n",
    "cfg = Munch.fromDict(yaml.safe_load(cfg_txt))\n",
    "logger = get_root_logger()\n",
    "\n",
    "model = SoftGroup(**cfg.model).cuda()\n",
    "logger.info(f'Load state dict from {args.checkpoint}')\n",
    "load_checkpoint(args.checkpoint, logger, model)\n",
    "\n",
    "dataset = build_dataset(cfg.data.test, logger)\n",
    "dataloader = build_dataloader(dataset, training=False, dist=args.dist, **cfg.dataloader.test)\n",
    "\n",
    "results = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for i, batch in tqdm(enumerate(dataloader), total=len(dataset)):\n",
    "        # Set params here so the model only takes coords and feats as input\n",
    "        model.set_params(**batch)\n",
    "        result = model(batch['coords_float'],batch['feats'])\n",
    "        results.append(result)\n",
    "        print(batch[ \"scan_ids\" ])\n",
    "        if i > 0:\n",
    "            break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show point cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import k3d\n",
    "def show_color_cloud(batch):\n",
    "    colors = (batch['feats'] + 1)/2*255\n",
    "    rgb = colors.cpu().numpy().astype(np.uint32)\n",
    "    colors_hex = (rgb[:,0]<<16) + (rgb[:,1]<<8) + (rgb[:,2])\n",
    "    coords = batch[\"coords_float\"].cpu().numpy()\n",
    "\n",
    "    plot = k3d.plot(grid_visible=False)\n",
    "    plot += k3d.points(coords, colors_hex, point_size=0.1, shader=\"simple\")\n",
    "    plot.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_color_cloud(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model.train()\n",
    "model.set_params(**batch)\n",
    "out = model(batch['coords_float'],batch['feats'])\n",
    "#print(out[:10])\n",
    "# N = number of points\n",
    "# K = number of classes\n",
    "print(out.shape) # N x K\n",
    "\n",
    "# Chose a random point of interest\n",
    "poi = 145 # [index, class]\n",
    "confidences = out[poi].cpu().numpy()\n",
    "plt.imshow(confidences.reshape(-1,1))\n",
    "plt.title(f\"Confidences for point of interest {poi}\")\n",
    "confidence, classification = out[poi].max(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import Saliency\n",
    "\n",
    "        \n",
    "model.train()\n",
    "model.set_params(**batch)\n",
    "\n",
    "def model_wrapper(coords_float, feats):\n",
    "    out = model(coords_float, feats)\n",
    "    return out[poi].reshape(1,-1)\n",
    "\n",
    "att = Saliency(model_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_attr, feat_attr = att.attribute((batch['coords_float'],batch['feats']), target = classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(batch['coords_float'].shape, batch['feats'].shape)\n",
    "print(coord_attr.shape, feat_attr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_attrs = (coord_attr + feat_attr).sum(axis=1)\n",
    "point_attrs.shape\n",
    "\n",
    "coords = batch[\"coords_float\"].detach().cpu().numpy()\n",
    "attrs = point_attrs.detach().cpu().numpy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show attribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "coords_plot = coords[attrs > 0]\n",
    "attrs_plot = attrs[attrs > 0]\n",
    "p1 = px.scatter_3d(x=coords_plot[:,0], y=coords_plot[:,1], z=coords_plot[:,2],\n",
    "                   size=attrs_plot,\n",
    "                   color=attrs_plot,\n",
    "                   opacity=0.8,\n",
    "                   color_continuous_scale='viridis')\n",
    "# p2 = go.Scatter3d(x=coords[:,0], y=coords[:,1], z=coords[:,2], mode=\"markers\",marker=dict(color=out.argmax(axis=1).cpu().numpy(), size=1, opacity=0.1))\n",
    "\n",
    "\n",
    "# p1.add_trace(p2)\n",
    "p1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "model.train()\n",
    "model.set_params(**batch)\n",
    "out = model(batch['coords_float'],batch['feats'])\n",
    "px.scatter_3d(x=coords[:,0], y=coords[:,1], z=coords[:,2],color=out.argmax(axis=-1).cpu().numpy().astype(np.int), color_discrete_map=\"category20\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "softgroup_pp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c176f5d7114dce7e56e18aa449730192889d0acf94cfa3760f893087531eb97f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
